---
title: "Final Project"
author: "Kanika Singh Sisodia"
date: "12/8/2019"
output:
  pdf_document
  
  
---
# 1. Loading required Libraries
```{r}
library(tidyverse)
library(rtweet)
library(lubridate)
library(kableExtra)
library(dplyr)
library(tm)
library(wordcloud)
library(twitteR)
library(tidytext)
library(syuzhet)
library(textdata)
library(RColorBrewer)
library(tinytex)
library(latexpdf)
```
# 2. Taking #Kashmir as the topic and pulling the latest 10000 tweets realated to it.
```{r message = FALSE}
#search.string <- "kashmir"
#no.of.tweets <- 10000

#tweets <- search_tweets(search.string, n=no.of.tweets, lang="en")
#dim(tweets)
```
# 3. Converting the raw tweets into a dataframe and writing them into a .csv file
```{r message = FALSE}
#tweets <- as.data.frame(tweets %>% select(1:5))
#write_csv(tweets, "/Users/rajsinghrathore/Desktop/K/Kashmir/Kashmir.csv")
```

# 4. Reading from the imported tweets
```{r}
Kashmir.df <- read.csv(file = "data/Kashmir.csv")
str(Kashmir.df)
```

# 5. Taking out the text part of the data and converting it into a corpus
```{r}
Kashmir.df$text <- as.character(Kashmir.df$text)
Kashmir.corpus <- Corpus(VectorSource(Kashmir.df$text))
inspect(Kashmir.corpus[66])
```
# 6. Cleaning the tweets
```{r}
Textprocessing <- function(x)
{gsub("http[[:alnum:]]*",'', x)
  gsub("http[^[:space:]]*", "", x) ## Remove URLs
  gsub('\\b+RT', '', x) ## Remove RT
  gsub('#\\S+', '', x) ## Remove Hashtags
  gsub('@\\S+', '', x) ## Remove Mentions
  gsub('[[:cntrl:]]', '', x) ## Remove Controls and special characters
  gsub("\\d", '', x) ## Remove Controls and special characters
  gsub("^[[:space:]]*","",x) ## Remove leading whitespaces
  gsub("[[:space:]]*$","",x) ## Remove trailing whitespaces
  
}
Kashmir.corpus <- tm_map(Kashmir.corpus,Textprocessing)
```


```{r}
dtm <- DocumentTermMatrix(Kashmir.corpus,
           control = list(stopwords = TRUE,
                          tolower = TRUE,
                          removeNumbers = TRUE,
                          removePunctuation = TRUE
                          ))
dtm
dim(dtm)

dtm <- as.data.frame(as.matrix(dtm))

```


# 7 Frequency Analysis
```{r}
freq <- colSums(dtm)
freq[1:10]
length(freq)
```
# 7.1 Ordering the frequencies to list the most frequent terms
```{r}
sort_freq <- sort(freq,decreasing = T)
head(sort_freq)
```

# 7.2 Plotting the 10 most frequent words
```{r}
jpeg("word.frequency.jpeg",  480, height = 480,
     pointsize = 12, quality = 75, bg = "white", res = NA)
 barplot(sort_freq[1:10], las = 2,
        col = brewer.pal(6,"Dark2"),ylim = c(0,14000), main ="Most frequent words",
        cex= 0.5,cex.names= 0.60,
        ylab = "Word frequencies")
 dev.off()
```
# 8 Wordcloud of the most common terms
```{r}
jpeg("wordcloud.jpeg", 480, height = 480,
     pointsize = 12, quality = 75, bg = "white", res = NA)
set.seed(110)
wordcloud(names(sort_freq),sort_freq, max.words = 150, colors = brewer.pal(6,"Spectral"))
dev.off()
```
# 9 Sentiment Analysis: Getting 8 different Emotions (Anger,anticipation disgust,fear,joy,sadness,surprise,trust) And their corresponding Valence From NRC Dictionary
```{r}
nrc <- get_nrc_sentiment(Kashmir.df$text)
head(nrc)
```
# 10. Barplot: Sentiment score for Kashmir
```{r}
jpeg("barplot1.jpeg", 480, height = 480,
     pointsize = 12, quality = 75, bg = "white", res = NA)
barplot(colSums(nrc), las =2,col = brewer.pal(n=10, name="RdBu"),ylim= c(0,12000), cex= 0.5,cex.names= 0.70,ylab = "count", main = "Sentiment Score for Kashmir") 
dev.off()

```

